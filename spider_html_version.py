"""
Bç«™çˆ¬è™« - ç®€åŒ–requestsç‰ˆæœ¬
ä½¿ç”¨requestsç›´æ¥çˆ¬å–é¡µé¢HTMLï¼Œæ— éœ€æµè§ˆå™¨
"""
import requests
import csv
import re
import time
from datetime import datetime
from bs4 import BeautifulSoup
import signal
import sys
import json

# å…¨å±€å˜é‡ç”¨äºæ§åˆ¶ç¨‹åºé€€å‡º
should_stop = False

def signal_handler(sig, frame):
    """å¤„ç†Ctrl+Cä¿¡å·"""
    global should_stop
    print('\n\nğŸ›‘ æ£€æµ‹åˆ°é€€å‡ºä¿¡å·...')
    should_stop = True
    print('âœ… ç¨‹åºå·²å®‰å…¨é€€å‡º')
    sys.exit(0)

# æ³¨å†Œä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGINT, signal_handler)

def get_videos_from_html(url, max_pages=10):
    """ä»HTMLé¡µé¢è§£æè§†é¢‘ä¿¡æ¯"""
    global should_stop
    
    print(f"ğŸš€ å¼€å§‹ä½¿ç”¨HTMLè§£ææ–¹å¼çˆ¬å–")
    print(f"ğŸ”— ç›®æ ‡URL: {url}")
    print("=" * 60)
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Cache-Control': 'max-age=0'
    }
    
    session = requests.Session()
    session.headers.update(headers)
    
    all_videos = []
    
    # å…ˆå°è¯•è·å–ç¬¬ä¸€é¡µï¼Œçœ‹çœ‹é¡µé¢ç»“æ„
    try:
        print("ğŸ“„ æ­£åœ¨è·å–ç¬¬1é¡µ...")
        response = session.get(url, timeout=15)
        response.raise_for_status()
        
        print(f"âœ“ é¡µé¢è·å–æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
        print(f"âœ“ é¡µé¢å¤§å°: {len(response.text)} å­—ç¬¦")
        
        # ä¿å­˜HTMLç”¨äºè°ƒè¯•
        with open("debug_page.html", "w", encoding="utf-8") as f:
            f.write(response.text)
        print("ğŸ“ é¡µé¢HTMLå·²ä¿å­˜åˆ° debug_page.html")
        
        # ä½¿ç”¨BeautifulSoupè§£æ
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # å°è¯•å¤šç§é€‰æ‹©å™¨æ‰¾è§†é¢‘é“¾æ¥
        selectors = [
            'a[href*="/video/BV"]',  # åŒ…å«BVå·çš„é“¾æ¥
            '.bili-cover-card',      # Bç«™å°é¢å¡ç‰‡
            '.video-card',           # è§†é¢‘å¡ç‰‡
            '.bili-video-card',      # Bç«™è§†é¢‘å¡ç‰‡
            'a[title]'               # æœ‰æ ‡é¢˜çš„é“¾æ¥
        ]
        
        videos_found = []
        for selector in selectors:
            elements = soup.select(selector)
            if elements:
                print(f"âœ“ ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                
                for element in elements:
                    href = element.get('href', '')
                    if '/video/BV' in href:
                        videos_found.append(element)
                        
                if videos_found:
                    break
        
        if not videos_found:
            print("âŒ æœªæ‰¾åˆ°è§†é¢‘é“¾æ¥ï¼Œå¯èƒ½éœ€è¦ç™»å½•æˆ–é¡µé¢ç»“æ„å·²å˜åŒ–")
            
            # å°è¯•æŸ¥æ‰¾é¡µé¢ä¸­çš„JSONæ•°æ®
            print("ğŸ” å°è¯•æŸ¥æ‰¾é¡µé¢ä¸­çš„JSONæ•°æ®...")
            
            # æŸ¥æ‰¾window.__INITIAL_STATE__æˆ–__RENDER_DATA__
            script_tags = soup.find_all('script')
            json_found = False
            
            for script in script_tags:
                # æ£€æŸ¥__RENDER_DATA__
                if script.get('id') == '__RENDER_DATA__':
                    print("âœ“ æ‰¾åˆ°__RENDER_DATA__")
                    try:
                        import urllib.parse
                        encoded_data = script.string or script.text
                        decoded_data = urllib.parse.unquote(encoded_data)
                        json_data = json.loads(decoded_data)
                        
                        with open("debug_render_data.json", "w", encoding="utf-8") as f:
                            json.dump(json_data, f, ensure_ascii=False, indent=2)
                        print("ğŸ“ RENDER_DATAå·²ä¿å­˜åˆ° debug_render_data.json")
                        json_found = True
                        
                    except Exception as e:
                        print(f"âŒ RENDER_DATAè§£æå¤±è´¥: {e}")
                
                # æ£€æŸ¥å…¶ä»–JavaScriptæ•°æ®
                elif script.string and any(keyword in script.string for keyword in ['__INITIAL_STATE__', 'window._render_data_', 'videoList']):
                    print("âœ“ æ‰¾åˆ°å¯èƒ½çš„è§†é¢‘æ•°æ®")
                    
                    # å°è¯•æå–JSON
                    json_patterns = [
                        r'window\.__INITIAL_STATE__\s*=\s*({.*?});',
                        r'window\._render_data_\s*=\s*({.*?});',
                        r'videoList\s*:\s*(\[.*?\])',
                        r'"vlist"\s*:\s*(\[.*?\])'
                    ]
                    
                    for pattern in json_patterns:
                        match = re.search(pattern, script.string, re.DOTALL)
                        if match:
                            try:
                                json_data = json.loads(match.group(1))
                                
                                with open("debug_extracted_data.json", "w", encoding="utf-8") as f:
                                    json.dump(json_data, f, ensure_ascii=False, indent=2)
                                print(f"ğŸ“ æå–çš„æ•°æ®å·²ä¿å­˜åˆ° debug_extracted_data.json")
                                
                                videos_from_json = extract_videos_from_json(json_data)
                                if videos_from_json:
                                    print(f"âœ“ ä»JSONæ•°æ®ä¸­æå–åˆ° {len(videos_from_json)} ä¸ªè§†é¢‘")
                                    return videos_from_json
                                json_found = True
                                break
                                
                            except json.JSONDecodeError as e:
                                print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                                continue
                
                if json_found:
                    break
            
            if not json_found:
                print("âŒ æœªæ‰¾åˆ°å¯è§£æçš„JSONæ•°æ®")
            
            # æœ€åå°è¯•ï¼šç›´æ¥è®¿é—®API
            print("ğŸ”„ å°è¯•ç›´æ¥è®¿é—®Bç«™API...")
            mid = re.search(r'/(\d+)/', url)
            if mid:
                mid = mid.group(1)
                api_videos = try_api_fallback(mid, session)
                if api_videos:
                    return api_videos
            
            return []
        
        # è§£æè§†é¢‘ä¿¡æ¯
        print(f"ğŸ“º å¼€å§‹è§£æ {len(videos_found)} ä¸ªè§†é¢‘...")
        
        for i, element in enumerate(videos_found, 1):
            if should_stop:
                break
                
            try:
                href = element.get('href', '')
                if not href:
                    continue
                    
                # å¤„ç†ç›¸å¯¹é“¾æ¥
                if href.startswith('//'):
                    href = 'https:' + href
                elif href.startswith('/'):
                    href = 'https://www.bilibili.com' + href
                
                # æå–BVå·
                bv_match = re.search(r'/video/(BV[\w]+)', href)
                if not bv_match:
                    continue
                    
                bv_id = bv_match.group(1)
                
                # è·å–æ ‡é¢˜
                title = (element.get('title') or 
                        element.get('aria-label') or 
                        element.text.strip() or 
                        f"è§†é¢‘_{bv_id}")
                
                video_info = {
                    'bvid': bv_id,
                    'title': title.strip(),
                    'url': href,
                    'page': 1
                }
                
                all_videos.append(video_info)
                
                if i % 10 == 0:
                    print(f"  å¤„ç†è¿›åº¦: {i}/{len(videos_found)}")
                    
            except Exception as e:
                print(f"âŒ è§£æè§†é¢‘ {i} å‡ºé”™: {e}")
                continue
        
        print(f"âœ… æˆåŠŸè§£æ {len(all_videos)} ä¸ªè§†é¢‘")
        return all_videos
        
    except requests.RequestException as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
        return []
    except Exception as e:
        print(f"âŒ è§£æè¿‡ç¨‹å‡ºé”™: {e}")
        return []

def extract_videos_from_json(json_data):
    """ä»JSONæ•°æ®ä¸­æå–è§†é¢‘ä¿¡æ¯"""
    videos = []
    
    try:
        # å°è¯•å¤šç§å¯èƒ½çš„JSONç»“æ„
        possible_paths = [
            ['videoData', 'list'],
            ['archive', 'list'],
            ['data', 'list', 'vlist'],
            ['page', 'list'],
            ['result', 'data']
        ]
        
        video_list = None
        for path in possible_paths:
            current = json_data
            try:
                for key in path:
                    current = current[key]
                if isinstance(current, list) and current:
                    video_list = current
                    print(f"âœ“ åœ¨è·¯å¾„ {' -> '.join(path)} æ‰¾åˆ°è§†é¢‘åˆ—è¡¨")
                    break
            except (KeyError, TypeError):
                continue
        
        if not video_list:
            print("âŒ æœªåœ¨JSONæ•°æ®ä¸­æ‰¾åˆ°è§†é¢‘åˆ—è¡¨")
            return []
        
        for item in video_list:
            try:
                bvid = item.get('bvid') or item.get('bv_id') or ''
                title = item.get('title') or item.get('name') or f"è§†é¢‘_{bvid}"
                
                if bvid:
                    videos.append({
                        'bvid': bvid,
                        'title': title.strip(),
                        'url': f"https://www.bilibili.com/video/{bvid}",
                        'play': item.get('play', 0),
                        'comment': item.get('comment', 0),
                        'page': 1
                    })
            except Exception as e:
                continue
                
    except Exception as e:
        print(f"âŒ JSONæ•°æ®è§£æå‡ºé”™: {e}")
    
    return videos

def try_api_fallback(mid, session):
    """å°è¯•ä½¿ç”¨ç®€åŒ–çš„APIä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
    try:
        print(f"ğŸ”— å°è¯•APIå¤‡é€‰æ–¹æ¡ˆï¼ŒUPä¸»ID: {mid}")
        
        # ç®€åŒ–çš„APIè¯·æ±‚
        api_url = f"https://api.bilibili.com/x/space/arc/search?mid={mid}&ps=30&tid=0&pn=1&keyword=&order=pubdate"
        
        response = session.get(api_url, timeout=10)
        if response.status_code == 200:
            data = response.json()
            
            if data.get('code') == 0:
                vlist = data.get('data', {}).get('list', {}).get('vlist', [])
                
                videos = []
                for video in vlist:
                    videos.append({
                        'bvid': video.get('bvid', ''),
                        'title': video.get('title', ''),
                        'url': f"https://www.bilibili.com/video/{video.get('bvid', '')}",
                        'play': video.get('play', 0),
                        'comment': video.get('comment', 0),
                        'page': 1
                    })
                
                if videos:
                    print(f"âœ“ APIå¤‡é€‰æ–¹æ¡ˆæˆåŠŸè·å– {len(videos)} ä¸ªè§†é¢‘")
                    return videos
                    
        print("âŒ APIå¤‡é€‰æ–¹æ¡ˆä¹Ÿå¤±è´¥äº†")
        return []
        
    except Exception as e:
        print(f"âŒ APIå¤‡é€‰æ–¹æ¡ˆå‡ºé”™: {e}")
        return []

def save_videos_csv(videos, filename=None):
    """ä¿å­˜è§†é¢‘åˆ°CSVæ–‡ä»¶"""
    if not videos:
        print("âŒ æ²¡æœ‰è§†é¢‘æ•°æ®å¯ä¿å­˜")
        return None
    
    if not filename:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"bilibili_videos_html_{timestamp}.csv"
    
    try:
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            fieldnames = ['åºå·', 'BVå·', 'è§†é¢‘æ ‡é¢˜', 'è§†é¢‘é“¾æ¥', 'æ’­æ”¾é‡', 'è¯„è®ºæ•°', 'é¡µç ']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for i, video in enumerate(videos, 1):
                writer.writerow({
                    'åºå·': i,
                    'BVå·': video['bvid'],
                    'è§†é¢‘æ ‡é¢˜': video['title'],
                    'è§†é¢‘é“¾æ¥': video['url'],
                    'æ’­æ”¾é‡': video.get('play', ''),
                    'è¯„è®ºæ•°': video.get('comment', ''),
                    'é¡µç ': video['page']
                })
        
        print(f"âœ… å·²ä¿å­˜ {len(videos)} ä¸ªè§†é¢‘åˆ° {filename}")
        return filename
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å‡ºé”™: {e}")
        return None

def main():
    global should_stop
    
    print("=" * 70)
    print("ğŸ¯ Bç«™UPä¸»è§†é¢‘çˆ¬å–å·¥å…· - HTMLè§£æç‰ˆæœ¬")
    print("ğŸ’¡ ç‰¹ç‚¹:")
    print("   - æ— éœ€æµè§ˆå™¨ï¼Œç›´æ¥è§£æHTML")
    print("   - æ”¯æŒCtrl+Cå®‰å…¨é€€å‡º")
    print("   - ç”Ÿæˆè°ƒè¯•æ–‡ä»¶ä¾¿äºåˆ†æ")
    print("=" * 70)
    
    # ç›®æ ‡URL
    url = "https://space.bilibili.com/93796936/video"
    
    print(f"ğŸ¯ ç›®æ ‡UPä¸»: {url}")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    start_time = datetime.now()
    
    try:
        # å¼€å§‹çˆ¬å–
        videos = get_videos_from_html(url)
        
        if videos and not should_stop:
            # ä¿å­˜ç»“æœ
            filename = save_videos_csv(videos)
            
            if filename:
                end_time = datetime.now()
                duration = end_time - start_time
                
                print("\n" + "=" * 70)
                print("ğŸ‰ çˆ¬å–å®Œæˆ!")
                print("=" * 70)
                print(f"âœ… æˆåŠŸè·å–: {len(videos)} ä¸ªè§†é¢‘")
                print(f"âœ… ä¿å­˜æ–‡ä»¶: {filename}")
                print(f"âœ… æ€»è€—æ—¶: {duration}")
                
                # æ˜¾ç¤ºå‰5ä¸ªè§†é¢‘é¢„è§ˆ
                print(f"\nğŸ“º è§†é¢‘é¢„è§ˆ:")
                for i, video in enumerate(videos[:5], 1):
                    title = video['title'][:50] + "..." if len(video['title']) > 50 else video['title']
                    print(f"{i}. {title}")
                
                if len(videos) > 5:
                    print(f"... è¿˜æœ‰ {len(videos) - 5} ä¸ªè§†é¢‘")
                    
        else:
            print("\nğŸ“ æ²¡æœ‰è·å–åˆ°è§†é¢‘æ•°æ®")
            print("ğŸ’¡ è¯·æ£€æŸ¥ debug_page.html å’Œ debug_data.json æ–‡ä»¶åˆ†æé—®é¢˜")
            
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
    finally:
        print("\nğŸ‘‹ ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    main()
