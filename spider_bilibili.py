import requests
from bs4 import BeautifulSoup
import re
import time
import csv
from urllib.parse import urljoin

def fetch_videos_selenium(url, max_videos=50):
    """
    ä½¿ç”¨seleniumæ‰¹é‡çˆ¬å–upä¸»çš„è§†é¢‘
    :param url: upä¸»è§†é¢‘é¡µé¢URL 
    :param max_videos: æœ€å¤§çˆ¬å–è§†é¢‘æ•°é‡
    :return: è§†é¢‘åˆ—è¡¨
    """
    try:
        from selenium import webdriver
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.webdriver.chrome.options import Options
        from selenium.common.exceptions import TimeoutException, NoSuchElementException
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.chrome.service import Service
        
        print(f"æ­£åœ¨ç”¨seleniumæ‰¹é‡çˆ¬å–: {url}")
        
        # Chromeé€‰é¡¹ - ä½¿ç”¨å·²ç™»å½•çš„æµè§ˆå™¨é…ç½®
        options = Options()
        # ä½¿ç”¨ç°æœ‰çš„Chromeç”¨æˆ·æ•°æ®ç›®å½•ï¼Œè¿™æ ·å¯ä»¥ä¿æŒç™»å½•çŠ¶æ€
        # æ³¨æ„ï¼šè¯·å…ˆæ‰‹åŠ¨ç™»å½•Chromeæµè§ˆå™¨å¹¶è®¿é—®Bç«™
        options.add_argument('--user-data-dir=C:/Users/Administrator/AppData/Local/Google/Chrome/User Data')
        options.add_argument('--profile-directory=Default')  # ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶
        
        # å¦‚æœä»éœ€è¦æ— å¤´æ¨¡å¼ï¼Œå¯ä»¥å¯ç”¨ä¸‹é¢è¿™è¡Œï¼ˆä½†å»ºè®®å…ˆæµ‹è¯•æœ‰å¤´æ¨¡å¼ï¼‰
        # options.add_argument('--headless')  
        
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')  # é¿å…è¢«æ£€æµ‹ä¸ºè‡ªåŠ¨åŒ–
        options.add_experimental_option("excludeSwitches", ["enable-automation"])  # ç§»é™¤è‡ªåŠ¨åŒ–æ ‡è¯†
        options.add_experimental_option('useAutomationExtension', False)  # ç¦ç”¨è‡ªåŠ¨åŒ–æ‰©å±•
        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # ä½¿ç”¨webdriver-managerè‡ªåŠ¨ç®¡ç†ChromeDriver
        try:
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
        except Exception as e:
            print(f"ä½¿ç”¨webdriver-managerå¯åŠ¨å¤±è´¥: {e}")
            print("å°è¯•ç›´æ¥ä½¿ç”¨Chrome...")
            driver = webdriver.Chrome(options=options)
        
        print("æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼Œæ­£åœ¨è®¿é—®é¡µé¢...")
        driver.get(url)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
        time.sleep(3)
        page_title = driver.title
        current_url = driver.current_url
        
        print(f"é¡µé¢æ ‡é¢˜: {page_title}")
        print(f"å½“å‰URL: {current_url}")
        
        # æ£€æŸ¥æ˜¯å¦è·³è½¬åˆ°ç™»å½•é¡µé¢
        if "ç™»å½•" in page_title or "login" in current_url.lower():
            print("âš ï¸  æ£€æµ‹åˆ°éœ€è¦ç™»å½•ï¼")
            print("è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
            print("1. æ‰‹åŠ¨åœ¨Chromeæµè§ˆå™¨ä¸­ç™»å½•Bç«™")
            print("2. ç¡®ä¿å¯ä»¥æ­£å¸¸è®¿é—®UPä¸»é¡µé¢")
            print("3. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
            print("ğŸ”„ ç»§ç»­å°è¯•çˆ¬å–ï¼ˆå¯èƒ½éœ€è¦æ‰‹åŠ¨åœ¨æµè§ˆå™¨ä¸­ç™»å½•ï¼‰...")
            # ç»™ç”¨æˆ·ä¸€äº›æ—¶é—´æ‰‹åŠ¨ç™»å½•ï¼Œè€Œä¸æ˜¯åœæ­¢ç¨‹åº
            time.sleep(10)
            # å°è¯•é‡æ–°è®¿é—®é¡µé¢
            driver.get(url)
            time.sleep(5)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        wait = WebDriverWait(driver, 10)
        
        videos = []
        page = 1
        consecutive_empty_pages = 0  # è¿ç»­ç©ºé¡µé¢è®¡æ•°å™¨
        
        while len(videos) < max_videos and consecutive_empty_pages < 3:
            print(f"æ­£åœ¨çˆ¬å–ç¬¬{page}é¡µ...")
            
            # ç­‰å¾…è§†é¢‘åˆ—è¡¨åŠ è½½
            time.sleep(2)
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨è·å–æ‰€æœ‰è§†é¢‘
            selectors = [
                "a.bili-cover-card",
                "a[href*='/video/BV']",
                "a[href*='bilibili.com/video']",
                ".video-card a",
                ".bili-video-card a"
            ]
            
            video_elements = []
            for selector in selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        video_elements = elements
                        print(f"ä½¿ç”¨é€‰æ‹©å™¨ {selector} æ‰¾åˆ° {len(elements)} ä¸ªè§†é¢‘")
                        break
                except:
                    continue
            
            if not video_elements:
                print(f"ç¬¬{page}é¡µæœªæ‰¾åˆ°è§†é¢‘å…ƒç´ ")
                consecutive_empty_pages += 1
                # å¦‚æœè¿ç»­å¤šé¡µéƒ½æ²¡æœ‰è§†é¢‘ï¼Œå¯èƒ½å·²ç»åˆ°åº•äº†
                if consecutive_empty_pages >= 3:
                    print("è¿ç»­3é¡µæ²¡æœ‰æ‰¾åˆ°è§†é¢‘ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                    break
                # ç»§ç»­å°è¯•ä¸‹ä¸€é¡µ
                page += 1
                continue
            else:
                consecutive_empty_pages = 0  # é‡ç½®è®¡æ•°å™¨
            
            # æå–å½“å‰é¡µé¢çš„è§†é¢‘ä¿¡æ¯
            current_page_videos = []
            for element in video_elements:
                try:
                    href = element.get_attribute('href')
                    if not href or '/video/BV' not in href:
                        continue
                        
                    bv_match = re.search(r'/video/(BV[\w]+)', href)
                    if not bv_match:
                        continue
                        
                    bv_id = bv_match.group(1)
                    
                    # è·å–è§†é¢‘æ ‡é¢˜ï¼ˆå°è¯•å¤šç§æ–¹å¼ï¼‰
                    title = ""
                    try:
                        # å°è¯•ä»titleå±æ€§è·å–
                        title = element.get_attribute('title')
                        if not title:
                            # å°è¯•ä»å­å…ƒç´ è·å–æ ‡é¢˜
                            title_selectors = [
                                '.bili-video-card__info--tit',
                                '.video-name',
                                '.title',
                                'p[title]',
                                '.info .title'
                            ]
                            for title_selector in title_selectors:
                                try:
                                    title_element = element.find_element(By.CSS_SELECTOR, title_selector)
                                    title = title_element.get_attribute('title') or title_element.text
                                    if title:
                                        break
                                except:
                                    continue
                        
                        if not title:
                            # æœ€åå°è¯•ä»aria-labelè·å–
                            title = element.get_attribute('aria-label') or f"è§†é¢‘_{bv_id}"
                            
                    except:
                        title = f"è§†é¢‘_{bv_id}"
                    
                    video_info = {
                        "bv": bv_id,
                        "url": href,
                        "title": title.strip(),
                        "page": page
                    }
                    
                    # é¿å…é‡å¤æ·»åŠ 
                    if not any(v["bv"] == bv_id for v in videos):
                        current_page_videos.append(video_info)
                        
                except Exception as e:
                    print(f"è§£æè§†é¢‘å…ƒç´ å‡ºé”™: {e}")
                    continue
            
            if not current_page_videos:
                print(f"ç¬¬{page}é¡µæ²¡æœ‰æ–°çš„è§†é¢‘")
                consecutive_empty_pages += 1
            else:
                consecutive_empty_pages = 0  # é‡ç½®è®¡æ•°å™¨
                videos.extend(current_page_videos)
                print(f"ç¬¬{page}é¡µè·å–äº† {len(current_page_videos)} ä¸ªè§†é¢‘ï¼Œæ€»è®¡: {len(videos)}")
                
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°ç›®æ ‡æ•°é‡
            if len(videos) >= max_videos:
                videos = videos[:max_videos]  # æˆªå–åˆ°æŒ‡å®šæ•°é‡
                break
            
            # å°è¯•ç¿»é¡µ
            try:
                # æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨ï¼Œè§¦å‘æ‡’åŠ è½½
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # å†æ¬¡æ»šåŠ¨ç¡®ä¿åŠ è½½å®Œæˆ
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰"åŠ è½½æ›´å¤š"æŒ‰é’®æˆ–ç¿»é¡µæŒ‰é’®
                load_more_selectors = [
                    ".load-more-btn",
                    ".pagination-btn-next", 
                    ".page-next",
                    "button[aria-label='ä¸‹ä¸€é¡µ']",
                    ".be-pager-next",
                    ".bili-pagination .bili-pagination-next"
                ]
                
                clicked = False
                for selector in load_more_selectors:
                    try:
                        button = driver.find_element(By.CSS_SELECTOR, selector)
                        if button.is_enabled() and button.is_displayed():
                            driver.execute_script("arguments[0].click();", button)
                            clicked = True
                            print(f"ç‚¹å‡»äº†ç¿»é¡µæŒ‰é’®: {selector}")
                            time.sleep(3)
                            break
                    except:
                        continue
                
                if not clicked:
                    # å¦‚æœæ²¡æœ‰ç¿»é¡µæŒ‰é’®ï¼Œå°è¯•ä¿®æ”¹URLç¿»é¡µ
                    next_page = page + 1
                    if "pn=" in url:
                        new_url = re.sub(r'pn=\d+', f'pn={next_page}', url)
                    else:
                        separator = "&" if "?" in url else "?"
                        new_url = f"{url}{separator}pn={next_page}"
                    
                    print(f"å°è¯•è®¿é—®ç¬¬{next_page}é¡µ: {new_url}")
                    driver.get(new_url)
                    time.sleep(3)
                
                page += 1
                
            except Exception as e:
                print(f"ç¿»é¡µå¤±è´¥: {e}")
                consecutive_empty_pages += 1
                if consecutive_empty_pages >= 3:
                    break
                page += 1
        
        driver.quit()
        print(f"çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(videos)} ä¸ªè§†é¢‘")
        return videos
            
    except ImportError:
        print("seleniumæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install selenium")
        return []
    except Exception as e:
        print(f"seleniumæ‰¹é‡çˆ¬å–é”™è¯¯: {e}")
        return []

def fetch_first_video(url):
    print(f"æ­£åœ¨çˆ¬å–: {url}")
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "DNT": "1",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Cache-Control": "max-age=0"
    }
    session = requests.Session()
    session.headers.update(headers)
    resp = session.get(url, timeout=15)
    resp.raise_for_status()
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")
    
    # è°ƒè¯•ï¼šä¿å­˜HTMLåˆ°æ–‡ä»¶æŸ¥çœ‹ç»“æ„
    with open("debug_html.html", "w", encoding="utf-8") as f:
        f.write(resp.text)
    print("HTMLå·²ä¿å­˜åˆ°debug_html.htmlï¼Œè¯·æ£€æŸ¥ç»“æ„")
    
    # å°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨
    selectors = [
        ("a.bili-cover-card", "bili-cover-cardç±»"),
        ("a[href*='/video/BV']", "åŒ…å«BVçš„é“¾æ¥"),
        ("a[href*='bilibili.com/video']", "Bç«™è§†é¢‘é“¾æ¥"),
        (".video-item a", "video-itemä¸‹çš„é“¾æ¥"),
        (".video-card a", "video-cardä¸‹çš„é“¾æ¥")
    ]
    
    for selector, desc in selectors:
        video_a = soup.select_one(selector)
        if video_a:
            print(f"ä½¿ç”¨é€‰æ‹©å™¨ {desc} æ‰¾åˆ°è§†é¢‘")
            break
    else:
        print("æ‰€æœ‰é€‰æ‹©å™¨éƒ½æœªæ‰¾åˆ°è§†é¢‘ï¼Œå¯èƒ½éœ€è¦JavaScriptæ¸²æŸ“")
        return None
    if video_a:
        href = video_a["href"]
        # å¤„ç†ç›¸å¯¹é“¾æ¥
        if href.startswith("//"):
            href = "https:" + href
        bv_match = re.search(r"/video/(BV[\w]+)", href)
        bv_id = bv_match.group(1) if bv_match else ""
        print(f"BVå·: {bv_id}")
        print(f"è§†é¢‘é“¾æ¥: {href}")
        return {"bv": bv_id, "url": href}
    else:
        print("æœªæ‰¾åˆ°è§†é¢‘æ¡ç›®")
        return None

def save_videos_to_csv(videos, filename="bilibili_videos.csv"):
    """
    å°†è§†é¢‘åˆ—è¡¨ä¿å­˜åˆ°CSVæ–‡ä»¶
    """
    if not videos:
        print("æ²¡æœ‰è§†é¢‘æ•°æ®å¯ä¿å­˜")
        return
        
    with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
        fieldnames = ['åºå·', 'BVå·', 'è§†é¢‘æ ‡é¢˜', 'è§†é¢‘é“¾æ¥', 'é¡µç ']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        writer.writeheader()
        for i, video in enumerate(videos, 1):
            writer.writerow({
                'åºå·': i,
                'BVå·': video['bv'],
                'è§†é¢‘æ ‡é¢˜': video['title'],
                'è§†é¢‘é“¾æ¥': video['url'],
                'é¡µç ': video['page']
            })
    
    print(f"å·²ä¿å­˜ {len(videos)} ä¸ªè§†é¢‘åˆ° {filename}")

if __name__ == "__main__":
    # åœ¨æ­¤å¡«å†™upä¸»ç©ºé—´urlï¼Œå¦‚ https://space.bilibili.com/xxxx/video
    up_url = "https://space.bilibili.com/93796936/upload/video"
    
    # è®¾ç½®è¦çˆ¬å–çš„è§†é¢‘æ•°é‡ - è®¾ç½®ä¸ºå¾ˆå¤§çš„æ•°å­—æ¥è·å–æ‰€æœ‰è§†é¢‘
    max_videos = 1000  # è®¾ç½®è¾ƒå¤§æ•°å­—ï¼Œå®é™…ä¼šåœ¨æ²¡æœ‰æ›´å¤šè§†é¢‘æ—¶è‡ªåŠ¨åœæ­¢
    
    print(f"å¼€å§‹æ‰¹é‡çˆ¬å–upä¸»è§†é¢‘ï¼Œç›®æ ‡æ•°é‡: {max_videos} (å®é™…ä¼šåœ¨æ²¡æœ‰æ›´å¤šè§†é¢‘æ—¶åœæ­¢)")
    print(f"UPä¸»é“¾æ¥: {up_url}")
    
    # ä½¿ç”¨seleniumæ‰¹é‡çˆ¬å–
    videos = fetch_videos_selenium(up_url, max_videos)
    
    if videos:
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_filename = f"bilibili_videos_all_{timestamp}.csv"
        
        # ä¿å­˜åˆ°CSVæ–‡ä»¶
        save_videos_to_csv(videos, csv_filename)
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªè§†é¢‘ä½œä¸ºç¤ºä¾‹
        print("\nå‰5ä¸ªè§†é¢‘ç¤ºä¾‹:")
        for i, video in enumerate(videos[:5], 1):
            print(f"{i}. {video['title']} - {video['bv']} - {video['url']}")
            
        print(f"\næ€»è®¡æˆåŠŸçˆ¬å– {len(videos)} ä¸ªè§†é¢‘")
    else:
        print("çˆ¬å–å¤±è´¥ï¼Œæ²¡æœ‰è·å–åˆ°è§†é¢‘æ•°æ®")
